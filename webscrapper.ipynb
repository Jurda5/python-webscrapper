{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re, os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "OUTPUT_DIR = 'output/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrappe_adresar_psychiatru_list_page(url):\n",
    "    df = pd.DataFrame(columns=['name', 'station', 'address', 'city', 'zip_code', 'phone', 'email', 'data_source'])\n",
    "\n",
    "    page = requests.get(url, verify=False)\n",
    "    soup = BeautifulSoup(page.text, \"html\")\n",
    "\n",
    "    names = soup.find_all('h2')\n",
    "    infos = soup.find_all('p')\n",
    "    infos = [info for info in infos if 'kontakt' in info.text.lower()]\n",
    "\n",
    "    for name_tag, info_tag in zip(names, infos):\n",
    "\n",
    "        name = name_tag.text\n",
    "        info = info_tag.text\n",
    "\n",
    "        # info_span = soup.find_all('span', {'data-name': name})[0]\n",
    "        # station = info_span['data-addressname']\n",
    "        # full_address = info_span['data-address']\n",
    "\n",
    "        # adress_items = full_address.split(' ')\n",
    "        # address = adress_items[0] + ' ' + adress_items[1]\n",
    "        # city = \" \".join(adress_items[2:])\n",
    "\n",
    "        station = None\n",
    "        address = None\n",
    "        city = None\n",
    "        zip_code = None\n",
    "        phone = None\n",
    "        email = None\n",
    "\n",
    "        address_lines_cnt = 0\n",
    "        for idx, line in enumerate(info.split('\\n')):\n",
    "\n",
    "            if \"kontakt\" in line.lower():\n",
    "                address_lines_cnt = 1\n",
    "                continue\n",
    "            if address_lines_cnt == 1:\n",
    "                station = line.strip()\n",
    "                if station.endswith(','):\n",
    "                    station = station.rstrip(',')\n",
    "                address_lines_cnt += 1\n",
    "                continue\n",
    "            if address_lines_cnt == 2:\n",
    "                address = line.strip()\n",
    "                if address.endswith(','):\n",
    "                    address = address.rstrip(',')\n",
    "                address_lines_cnt += 1\n",
    "                continue\n",
    "            if address_lines_cnt == 3:\n",
    "                city_line = line.strip().split(' ')\n",
    "                city = \" \".join(city_line[2:])\n",
    "                zip_code = \"\".join(c for c in city_line[:2] if c.isdigit())\n",
    "                address_lines_cnt += 1\n",
    "                continue\n",
    "            if \"tel.:\" in line:\n",
    "                phone = re.sub(r'[^\\d\\+]', '', line)\n",
    "                continue\n",
    "            if \"e-mail:\" in line:\n",
    "                email = line.split(':')[1].strip()\n",
    "                continue\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([{\n",
    "            'name': name,\n",
    "            'station': station,\n",
    "            'address': address,\n",
    "            'city': city,\n",
    "            'zip_code': zip_code,\n",
    "            'phone': phone,\n",
    "            'email': email,\n",
    "            'data_source': 'https://adresar-psychiatru.nudz.cz/'\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_psychologove = pd.DataFrame(columns=['name', 'station', 'address', 'city', 'zip_code', 'phone', 'email', 'data_source'])\n",
    "df_psichiatri = pd.DataFrame(columns=['name', 'station', 'address', 'city', 'zip_code', 'phone', 'email', 'data_source'])\n",
    "\n",
    "for page_number in range(1, 13):\n",
    "    url = f\"https://adresar-psychiatru.nudz.cz/psycholog/seznam?page={page_number}&do=listChange\"\n",
    "    df_psychologove = pd.concat([df_psychologove, scrappe_adresar_psychiatru_list_page(url)], ignore_index=True)\n",
    "\n",
    "for page_number in range(1, 20):\n",
    "    url = f\"https://adresar-psychiatru.nudz.cz/psychiatr/seznam?page={page_number}&do=listChange\"\n",
    "    df_psichiatri = pd.concat([df_psichiatri, scrappe_adresar_psychiatru_list_page(url)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrappe_dusevnizdravi_vzp_db(base_url, list_page_url):\n",
    "\n",
    "    df = pd.DataFrame(columns=['name', 'station', 'address', 'city', 'zip_code', 'phone', 'email', 'data_source'])\n",
    "\n",
    "    page = requests.get(base_url+list_page_url, verify=False)\n",
    "    soup = BeautifulSoup(page.text, \"html\")\n",
    "\n",
    "    table = soup.find_all('tbody', class_='ContractsTable-body')[0]\n",
    "\n",
    "    table_rows = table.find_all('tr')\n",
    "\n",
    "    name = None\n",
    "    station = None\n",
    "    address = None\n",
    "    city = None\n",
    "    zip_code = None\n",
    "    phone = None\n",
    "    email = None\n",
    "\n",
    "    for table_row in table_rows:\n",
    "        t_url = table_row.find_all('a')[0]['href']\n",
    "        t_page = requests.get(base_url+t_url, verify=False)\n",
    "        t_soup = BeautifulSoup(t_page.text, \"html\")\n",
    "\n",
    "        name = t_soup.find_all('h2', class_=\"Heading Heading--h2\")[0].text\n",
    "\n",
    "        t_table = t_soup.find_all('tbody', class_=\"ContractsDetailTable-body\")[0]\n",
    "        t_table_rows = t_table.find_all('td')\n",
    "\n",
    "        for idx, t_table_row in enumerate(t_table_rows):\n",
    "            if idx == 0:\n",
    "                station = t_table_row.text.strip()\n",
    "                continue\n",
    "            if idx == 1:\n",
    "                tmp = t_table_row.text.strip().replace('\\t', '').replace('\\r', '').split('\\n')\n",
    "                address = tmp[0].strip()\n",
    "                city = \" \".join(tmp[1].split(' ')[1:])\n",
    "                zip_code = tmp[1].split(' ')[0]\n",
    "                continue\n",
    "            if idx == 4:\n",
    "                phone = t_table_row.text.strip()\n",
    "                continue\n",
    "            if idx == 5:\n",
    "                email = t_table_row.text.strip()\n",
    "                break\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([{\n",
    "            'name': name,\n",
    "            'station': station,\n",
    "            'address': address,\n",
    "            'city': city,\n",
    "            'zip_code': zip_code,\n",
    "            'phone': phone,\n",
    "            'email': email,\n",
    "            'data_source': base_url\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vzp = pd.DataFrame(columns=['name', 'station', 'address', 'city', 'zip_code', 'phone', 'email', 'data_source'])\n",
    "\n",
    "base_url = \"https://dusevnizdravi.vzp.cz\"\n",
    "\n",
    "for page_number in range(1, 75):\n",
    "    list_page_url = f\"/seznam-terapeutu/?queryKraj=&queryZamereni=&queryForma=&queryKapacita=&queryText=&stranka={page_number}\"\n",
    "    df_vzp = pd.concat([df_vzp, scrappe_dusevnizdravi_vzp_db(base_url, list_page_url)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrappe_hledampsychologa_db(base_url, list_page_url):\n",
    "\n",
    "    df = pd.DataFrame(columns=['name', 'station', 'address', 'city', 'zip_code', 'phone', 'email', 'data_source'])\n",
    "\n",
    "    page = requests.get(base_url+list_page_url, verify=False)\n",
    "    soup = BeautifulSoup(page.text, \"html\")\n",
    "\n",
    "    results = soup.find_all('div', class_='vysledek')\n",
    "\n",
    "    name = None\n",
    "    station = None\n",
    "    address = None\n",
    "    city = None\n",
    "    zip_code = None\n",
    "    phone = None\n",
    "    email = None\n",
    "    link = None\n",
    "\n",
    "    for result in results:\n",
    "        t_url = result.find_all('a')[0]['href']\n",
    "        t_page = requests.get(base_url+t_url, verify=False)\n",
    "        t_soup = BeautifulSoup(t_page.text, \"html\")\n",
    "\n",
    "        name = t_soup.find_all('h2', class_=\"profil__name\")[0].text\n",
    "\n",
    "        items = t_soup.find_all('div', class_=\"item\")\n",
    "        for item in items:\n",
    "            item_imgs = item.find_all('img')\n",
    "            if len(item_imgs) == 0:\n",
    "                continue\n",
    "\n",
    "            item_img_src = item_imgs[0]['src']\n",
    "            if 'tel.svg' in item_img_src:\n",
    "                phone = item.find_all('p')[0].text.strip()\n",
    "            if 'home.svg' in item_img_src:\n",
    "                full_address = item.find_all('p')[0].text.strip()\n",
    "                address_parts = full_address.split(',')\n",
    "\n",
    "                if len(address_parts) > 1:\n",
    "                    address = address_parts[0].strip()\n",
    "                    address = address if not '(ulice) (popisnÃ©)' in address else None\n",
    "                    city = address_parts[1].strip()\n",
    "                else:\n",
    "                    city = address_parts[0].strip()\n",
    "            if 'link.svg' in item_img_src:\n",
    "                link = item.find_all('a')[0].text.strip()\n",
    "   \n",
    "        df = pd.concat([df, pd.DataFrame([{\n",
    "            'name': name,\n",
    "            'station': station,\n",
    "            'address': address,\n",
    "            'city': city,\n",
    "            'zip_code': zip_code,\n",
    "            'phone': phone,\n",
    "            'email': email,\n",
    "            'data_source': base_url\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hledampsychologa = pd.DataFrame(columns=['name', 'station', 'address', 'city', 'zip_code', 'phone', 'email', 'data_source'])\n",
    "\n",
    "for fieldId in range(1, 18):\n",
    "\n",
    "    base_url = f\"https://hledampsychologa.cz\"\n",
    "    list_page_url = f\"/search-result/?fieldId={fieldId}1&regionId=0\"\n",
    "\n",
    "    df_hledampsychologa = pd.concat([df_hledampsychologa, scrappe_hledampsychologa_db(base_url, list_page_url)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_psychologove = pd.concat([df_psychologove, df_vzp, df_hledampsychologa], ignore_index=True)\n",
    "df_all_psichiatri = pd.concat([df_psichiatri], ignore_index=True)\n",
    "\n",
    "df_all_psychologove.to_csv(OUTPUT_DIR + 'psychologove.csv', index=False, sep=';')\n",
    "df_all_psichiatri.to_csv(OUTPUT_DIR + 'psichiatri.csv', index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
